{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sashikiran-76/LLM_for_medical_QA/blob/main/Data_prep_and_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation and conversion into json"
      ],
      "metadata": {
        "id": "wnbL0lFi_jDG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clq6yTTXsRdL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# import docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5u4VTZSsW8s",
        "outputId": "a7bb1c98-92c1-4825-a67b-8ade54dbca00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive\")"
      ],
      "metadata": {
        "id": "GkcBBGYikZwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vpej5MVsRdM"
      },
      "outputs": [],
      "source": [
        "# del text\n",
        "with open(\"/content/Dr. Khalid's explanation of 1700 MCQ AUG 18.txt\", encoding='latin-1') as file:\n",
        "    text = file.readlines()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxO_yqdLsRdN"
      },
      "outputs": [],
      "source": [
        "# del text\n",
        "# # text = docx2txt.process(\"/Users/tarakantamishra/Downloads/Dr. Khalid's explanation of 1700 MCQ AUG 18.docx\")\n",
        "# print (text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdsF1QVusRdN"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "# del begin_with\n",
        "# begin_with = re.compile(r\"^(A |An )\")\n",
        "# begin_with = re.compile(r\"^\\d{1,4}\\.\\s{0,4}A\\s|^\\d{0,4}\\.\\s{1,4}An\\s|^\\d{1,4}\\.\\s{0,4}Pt\\s|^\\d{1,4}\\.\\s{0,4}In\\s|^\\d{1,4}\\.\\s{0,4}The\\s\")\n",
        "begin_with_digit = re.compile(r\"^\\d{1,4}\\.\\s{0,4}.*\")\n",
        "begin_with_q = re.compile(r\"^Q\")\n",
        "end_with = re.compile(r\"^.*\\?\\s|^.*:\\s\")\n",
        "                    #   \"(?)$\")\n",
        "# check = re.compile(r\"(.* ?)$\")\n",
        "ans = re.compile('Ans.\\s{0,4}[a-zA-z]|Ans.\\s{0,4}[1]\\.\\s{0,3}[a-zA-z]')\n",
        "sub_ans = re.compile('Ans\\.\\s\\d{1,4}\\.\\s')\n",
        "option = re.compile('^[a-z]\\s{0,4}\\.\\s{0,4}')\n",
        "\n",
        "if re.match(begin_with_digit,'58. A 16m child presents with drooling, sore throat and loss of voice. He has fever with a temp of\\n'):\n",
        "    print ('match1')\n",
        "    search_result = re.search( begin_with_digit, '11. An 18yo female ')\n",
        "    print (search_result.start())\n",
        "\n",
        "if re.match(ans,'Ans. 1.The key is C. Call anesthesiologist.'):\n",
        "    print ('match ans')\n",
        "\n",
        "if re.match(begin_with_q, 'Q. vinrbhibhr ?'):\n",
        "  print ('match Q')\n",
        "\n",
        "if re.match(end_with,'1.A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step:\\n'):\n",
        "    print ('match2')\n",
        "\n",
        "if re.match(sub_ans, 'Ans. 1. nvjhviuhirv'):\n",
        "  print ('sub answr match')\n",
        "\n",
        "if re.match(option, 'a. Ceftriaxone\\n'):\n",
        "  print ('option match')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[722:735]"
      ],
      "metadata": {
        "id": "slXFrfk15erD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJIC0i4QsRdO"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "ans_list, quest_list, opt_list = [], [], []\n",
        "quest_num_list, ans_num_list, option_num_list = [], [], []\n",
        "for index, line in enumerate(text):\n",
        "    if re.match(begin_with_digit, line):\n",
        "        # cnt_quest+=1\n",
        "        # print ('quest begin', index, line)\n",
        "        # if int(quest_num)==58:\n",
        "        #   print ('enterq',line)\n",
        "        #   break\n",
        "      quest_list.append(index)\n",
        "      quest_num = line.split('.')[0]\n",
        "      quest_num_list.append(int(quest_num))\n",
        "\n",
        "    # if re.match(begin_with_q, line):\n",
        "    #   print ('sub quest begin', index, line)\n",
        "    #   quest_list.append(index)\n",
        "    if re.match(option, line):\n",
        "      opt_list.append(index)\n",
        "      option_num_list.append(int(quest_num))\n",
        "\n",
        "    if re.match(ans, line):\n",
        "        # cnt_ans+=1\n",
        "        # print ('Ans is', index,line)\n",
        "      if int(quest_num)==86:\n",
        "        # print ('enter',line)\n",
        "        break\n",
        "      ans_list.append(index)\n",
        "      ans_num_list.append(int(quest_num))\n",
        "\n",
        "    # if re.match(sub_ans, line):\n",
        "    #   print ('Sub ans is', index, line)\n",
        "    #   ans_list.append(index)\n",
        "\n",
        "    if re.match(end_with, line):\n",
        "        # cnt_quest+=1\n",
        "        # print ('quest end', index, line)\n",
        "      quest_list.append(index)\n",
        "      quest_num_list.append(int(quest_num))\n",
        "\n",
        "# clear_output()\n",
        "print (len(ans_list), len(ans_num_list),\n",
        "       len(quest_list),len(quest_num_list),\n",
        "       len(opt_list), len(option_num_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe6gdL9vsRdP"
      },
      "outputs": [],
      "source": [
        "absent_quest, absent_ans, absent_option = [], [], []\n",
        "for i in range(1,1708):\n",
        "  if (i not in quest_num_list) :\n",
        "    absent_quest.append(i)\n",
        "  if (i not in ans_num_list) :\n",
        "    absent_ans.append(i)\n",
        "  if (i not in option_num_list):\n",
        "    absent_option.append(i)\n",
        "print (len(absent_quest), len(absent_ans), len(absent_option))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# absent_ans, absent_quest, absent_option\n",
        "# quest_num_list.index(58)\n",
        "text[105:113]"
      ],
      "metadata": {
        "id": "HdDd9Zjp2I-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quest_num_list[20:30], quest_list[20:30]"
      ],
      "metadata": {
        "id": "cNz1Sv3FVn4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_list = []\n",
        "start_pos = 0\n",
        "stop_pos = len(quest_list)\n",
        "next_index = 0\n",
        "current_position = 0\n",
        "\n",
        "for i in range(1,1707):\n",
        "  if i in absent_quest:\n",
        "    print (i)\n",
        "    questions_list.append([])\n",
        "    continue\n",
        "  first_index = quest_list[quest_num_list.index(i)]\n",
        "  # print (option_num_list.index(i))\n",
        "  next_index = quest_list[quest_num_list.index(i)+1]\n",
        "  # print (first_index, next_index)\n",
        "  # print (text[first_index:next_index+1])\n",
        "  questions_list.append(text[first_index:next_index+1])\n",
        "# clear_output()\n",
        "print (len(questions_list))"
      ],
      "metadata": {
        "id": "JiH0_tumZLPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_list[14:16]"
      ],
      "metadata": {
        "id": "YHciH64H3g5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsX5xo6NsRdP"
      },
      "outputs": [],
      "source": [
        "# questions_list = []\n",
        "# start_pos = 0\n",
        "# stop_pos = len(quest_list)\n",
        "# next_index = 0\n",
        "# current_index = 0\n",
        "# for position, index in enumerate(quest_list[start_pos:stop_pos], start=start_pos):\n",
        "#     if (index-next_index>-1):\n",
        "#         # print (start_pos, start_pos+1, index, position)\n",
        "#         # print ('text[index]',text[index])\n",
        "#         if re.match(begin_with_q, text[index]) or not(re.match(begin_with_digit, text[index])):\n",
        "#           # print ('sub quest or not part of quest')\n",
        "#           continue\n",
        "\n",
        "#         # elif re.match(ans, text[index]) or re.match(sub_ans, text[index]):\n",
        "#         #   # print ('sub answer or answer')\n",
        "#         #   continue\n",
        "\n",
        "#         elif (re.match(end_with, text[index])):\n",
        "#           # print ('same line')\n",
        "#           next_index = index+1\n",
        "#           enter_sub_quest_loop = 0\n",
        "#           current_index = index\n",
        "\n",
        "#         else:\n",
        "#           # print ('multiline')\n",
        "#           next_index = (quest_list+[1000000])[position+1]+1\n",
        "#           enter_sub_quest_loop = 0\n",
        "#           current_index = index\n",
        "\n",
        "#         # print (current_index, next_index)\n",
        "#         questions_list.append(text[current_index:next_index])\n",
        "\n",
        "\n",
        "# # clear_output()\n",
        "# len(questions_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers_list = []\n",
        "start_pos = 0\n",
        "stop_pos = len(answers_list)\n",
        "next_index = 0\n",
        "current_position = 0\n",
        "\n",
        "for i in range(1,1707):\n",
        "  if i in absent_ans:\n",
        "    answers_list.append([])\n",
        "    continue\n",
        "  first_index = ans_list[ans_num_list.index(i)]\n",
        "  # print (option_num_list.index(i))\n",
        "  for j, ans_index in enumerate(ans_list[ans_num_list.index(i):], start=ans_num_list.index(i)):\n",
        "    if ans_num_list[j]!=i:\n",
        "      last_index = ans_list[j-1]\n",
        "      # print (j,first_index, last_index)\n",
        "      # print (text[first_index:last_index+1])\n",
        "      break\n",
        "    else :\n",
        "      continue\n",
        "  # print (i, first_index, last_index)\n",
        "  # print (text[first_index:last_index])\n",
        "  answers_list.append(text[first_index:last_index+1])\n",
        "  # print (\"values appended\")\n",
        "\n",
        "clear_output()\n",
        "print (len(answers_list))"
      ],
      "metadata": {
        "id": "PORpwu9XYcOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# answers_list = []\n",
        "# start_pos = 0\n",
        "# stop_pos = len(ans_list)\n",
        "# next_index = 0\n",
        "# current_position = 0\n",
        "# for position, index in enumerate(ans_list[start_pos:stop_pos], start=start_pos):\n",
        "#     if index in absent_ans:\n",
        "#       print (index)\n",
        "#       answers_list.append([])\n",
        "#     for i, quest_index in enumerate(quest_list[current_position:]):\n",
        "#       # print (quest_index, index)\n",
        "#       if quest_index>index:\n",
        "#         # print ('enter')\n",
        "#         next_index = quest_index\n",
        "#         current_position = i\n",
        "#         break\n",
        "#       else :\n",
        "#         continue\n",
        "\n",
        "#     if re.match(ans, text[index]):\n",
        "#       # print ('index, next-index', index, next_index)\n",
        "#       # print ('ans found')\n",
        "#       answers_list.append(text[index:next_index-1])\n",
        "#       # print ('Ans is', text[index:next_index-1])\n",
        "#     else :\n",
        "#       continue\n",
        "\n",
        "\n",
        "#     # if i%100==0:\n",
        "# # clear_output()\n",
        "# print (len(answers_list))"
      ],
      "metadata": {
        "id": "w6a7GId8BjsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUaI0wlPsRdQ"
      },
      "outputs": [],
      "source": [
        "# ans_list[5:15], ans_num_list[5:15], quest_list[18:30], quest_num_list[18:30]\n",
        "# ans_list[1428], quest_list[3676]\n",
        "text[340:345]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_list[44:50], option_num_list[43:50]\n"
      ],
      "metadata": {
        "id": "PKYyy8rHC-gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options_list = []\n",
        "start_pos = 0\n",
        "stop_pos = len(options_list)\n",
        "next_index = 0\n",
        "current_position = 0\n",
        "\n",
        "for i in range(1,1707):\n",
        "  if i in absent_option:\n",
        "    options_list.append([])\n",
        "    continue\n",
        "  first_index = opt_list[option_num_list.index(i)]\n",
        "  # print (option_num_list.index(i))\n",
        "  for j, option_index in enumerate(opt_list[option_num_list.index(i):], start=option_num_list.index(i)):\n",
        "    if option_num_list[j]!=i:\n",
        "      last_index = opt_list[j-1]\n",
        "      # print (j,first_index, last_index)\n",
        "      # print (text[first_index:last_index+1])\n",
        "      break\n",
        "    else :\n",
        "      continue\n",
        "  # print (i, first_index, last_index)\n",
        "  # print (text[first_index:last_index])\n",
        "  options_list.append(text[first_index:last_index+1])\n",
        "  print (\"values appended\")\n",
        "\n",
        "\n",
        "\n",
        "clear_output()\n",
        "print (len(options_list))"
      ],
      "metadata": {
        "id": "qMZdPuhg975b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options_list[10], questions_list[10], answers_list[10]"
      ],
      "metadata": {
        "id": "5IKkb5Ww8e9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "absent_options[0:10], quest_list[35:37], ans_list[14]\n",
        "# quest_num_list.index(15), ans_num_list.index(15)"
      ],
      "metadata": {
        "id": "OGXHldgn8Zgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXUwHJfzsRdQ"
      },
      "outputs": [],
      "source": [
        "# options_list = []\n",
        "# start_index = 0\n",
        "# for q_position, q_index in enumerate(quest_list):\n",
        "#   if q_index == start_index-1:\n",
        "#     continue\n",
        "#   else:\n",
        "#     if re.search(end_with ,text[q_index]):\n",
        "#       # print (text[q_index+1])\n",
        "#       start_index = q_index+1\n",
        "#       current_question_num = quest_num_list[q_position]\n",
        "#       for a_position, a_index in enumerate(ans_list):\n",
        "#         if (a_index>start_index) and ('Ans.' in text[a_index]):\n",
        "#           end_index = a_index\n",
        "#           print (text[start_index:end_index])\n",
        "#           break\n",
        "#         else:\n",
        "#           continue\n",
        "#     else:\n",
        "#       continue\n",
        "#   print (start_index, end_index, q_index)\n",
        "#   options_list.append(text[start_index:end_index])\n",
        "#   print (text[start_index:end_index])\n",
        "  # if q_position%100==5:\n",
        "  #   print (q_position)\n",
        "  #   break\n",
        "\n",
        "# clear_output()\n",
        "\n",
        "print (len(options_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Erb_KFsRdQ"
      },
      "outputs": [],
      "source": [
        "len(options_list), len(questions_list), len(answers_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "for quest, option, answer in zip(questions_list, options_list, answers_list):\n",
        "  all_data.append({'question':quest, 'options':option, 'answer':answer})\n",
        "len(all_data)"
      ],
      "metadata": {
        "id": "kwh7ioL_LJ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Serialisation\"\n",
        "json_obj = json.dumps(\n",
        "    all_data,\n",
        "    indent=4\n",
        "  )"
      ],
      "metadata": {
        "id": "rgfC3BQSJmOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data_12Jun.json', 'a') as f:\n",
        "  f.write(json_obj)"
      ],
      "metadata": {
        "id": "0KiZZ6k2lGuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading JSON and inferencing LLM's**"
      ],
      "metadata": {
        "id": "GpeEla9i0M8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DZ4a1bCoK3ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del qa_data\n",
        "# qa_data = pd.read_json('/content/data_12Jun_edited.json')\n",
        "qa_data = pd.read_csv('/content/Data_with_question_sentences(19Jul).csv')\n",
        "\n",
        "qa_data.head()"
      ],
      "metadata": {
        "id": "w1g0oSoVjR11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "6bd2b2b4-50af-4203-8d7e-9ec51380b20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                           question  \\\n",
              "0           0  ['1. A 65yo man presents with painless hematur...   \n",
              "1           1  ['2. A 74yo smoker presented to his GP with co...   \n",
              "2           2  ['3. A 44yo woman has lost weight over 12 mont...   \n",
              "3           3  ['4. A 79yo anorexic male complains of thirst ...   \n",
              "4           4  ['5. A 64yo man has recently suffered from an ...   \n",
              "\n",
              "                                             options  \\\n",
              "0  ['a. US Abdomen\\n', 'b. Flexible cystoscopy\\n'...   \n",
              "1  ['a. Pseudocushing syndrome\\n', 'b. Conns dise...   \n",
              "2  ['a. Thyroid antibodies\\n', 'b. TFT\\n', 'c. EC...   \n",
              "3  ['a. BPH\\n', 'b. Prostate carcinoma\\n', 'c. Ch...   \n",
              "4  ['a. Lofepramine\\n', 'b. Dosulepin\\n', 'c. Cit...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  ['Ans. The key is B. Flexible cystoscopy. [Pai...   \n",
              "1  ['Ans. The key is C. Ectopic ACTH. [The patien...   \n",
              "2  ['Ans. The key is B. TFT. [The patient has par...   \n",
              "3       ['Ans. The key is B. Prostate Carcinoma.\\n']   \n",
              "4  ['Ans. The key is C. Citalopram. [Among SSRIs ...   \n",
              "\n",
              "                              question_sentence  \n",
              "0       What is the most appropriate next step?  \n",
              "1                 What is the most probable dx?  \n",
              "2  What is the most appropriate inv to be done?  \n",
              "3                 What is the most probable dx?  \n",
              "4              What is the most appropriate tx?  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a1e4e853-7b30-44fe-bf4a-b579b61962dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>question</th>\n",
              "      <th>options</th>\n",
              "      <th>answer</th>\n",
              "      <th>question_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>['1. A 65yo man presents with painless hematur...</td>\n",
              "      <td>['a. US Abdomen\\n', 'b. Flexible cystoscopy\\n'...</td>\n",
              "      <td>['Ans. The key is B. Flexible cystoscopy. [Pai...</td>\n",
              "      <td>What is the most appropriate next step?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>['2. A 74yo smoker presented to his GP with co...</td>\n",
              "      <td>['a. Pseudocushing syndrome\\n', 'b. Conns dise...</td>\n",
              "      <td>['Ans. The key is C. Ectopic ACTH. [The patien...</td>\n",
              "      <td>What is the most probable dx?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>['3. A 44yo woman has lost weight over 12 mont...</td>\n",
              "      <td>['a. Thyroid antibodies\\n', 'b. TFT\\n', 'c. EC...</td>\n",
              "      <td>['Ans. The key is B. TFT. [The patient has par...</td>\n",
              "      <td>What is the most appropriate inv to be done?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>['4. A 79yo anorexic male complains of thirst ...</td>\n",
              "      <td>['a. BPH\\n', 'b. Prostate carcinoma\\n', 'c. Ch...</td>\n",
              "      <td>['Ans. The key is B. Prostate Carcinoma.\\n']</td>\n",
              "      <td>What is the most probable dx?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>['5. A 64yo man has recently suffered from an ...</td>\n",
              "      <td>['a. Lofepramine\\n', 'b. Dosulepin\\n', 'c. Cit...</td>\n",
              "      <td>['Ans. The key is C. Citalopram. [Among SSRIs ...</td>\n",
              "      <td>What is the most appropriate tx?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1e4e853-7b30-44fe-bf4a-b579b61962dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-67740ee7-b709-47b3-baf8-e29a0fd1a5c3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67740ee7-b709-47b3-baf8-e29a0fd1a5c3')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-67740ee7-b709-47b3-baf8-e29a0fd1a5c3 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1e4e853-7b30-44fe-bf4a-b579b61962dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1e4e853-7b30-44fe-bf4a-b579b61962dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def context(question,sentence):\n",
        "  context_var = question.replace(sentence, '')\n",
        "  return context_var"
      ],
      "metadata": {
        "id": "t20iUnSl2sBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qa_data['context'] = ''\n",
        "context_list = []\n",
        "for i,row in qa_data.iterrows():\n",
        "  temp_value = context(row['question'], row['question_sentence'])\n",
        "  context_list.append(temp_value)\n",
        "  # print(temp_value)\n",
        "print (len(context_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw0_O309Q2i_",
        "outputId": "5e132904-eefb-41a1-b57a-8a558ea9157c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['context'] = context_list"
      ],
      "metadata": {
        "id": "szEIkN315SSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['context'][180] = str(['181.A 28yo woman at 39wk gestation is in labor. She develops abdominal pain and HR=125bpm,\\\n",
        "BP=100/42mmHg, temp=37.2C and saturation=99%. Exam: lower abdomen is exquisitely tender.\\\n",
        "CTG=prv normal, now showing reduced variability and late deceleration develops with slow\\\n",
        "recovery. She has had 1 prv LSCS for a breech baby. \\\n",
        "complication for this lady?'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWfCXvsXfKC3",
        "outputId": "e3ceb26e-1a77-474e-b83f-1bcd00d8ae30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-70dc7079ccce>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  qa_data['context'][180] = str(['181.A 28yo woman at 39wk gestation is in labor. She develops abdominal pain and HR=125bpm,\\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['context'][1555] = str(['1556. A 43yo woman has suffered with heavy periods for many years and has tried many medical tx without success. She is constantly flooding and at times cant leave her house due to heavy bleeding. She has completed her family of 5 children and her last blood test showed Hgb=8.9g/dl. She feels that she cant cope with the bleeding anymore and her husband is asking for a tx that can guarantee success. What is the most appropriate management to improve menorrhagia in this pt? \\n'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdRGs-VPrqs_",
        "outputId": "a467050f-e076-4dc3-a1d5-4692adb99dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-9681eefa381b>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  qa_data['context'][1555] = str(['1556. A 43yo woman has suffered with heavy periods for many years and has tried many medical tx without success. She is constantly flooding and at times cant leave her house due to heavy bleeding. She has completed her family of 5 children and her last blood test showed Hgb=8.9g/dl. She feels that she cant cope with the bleeding anymore and her husband is asking for a tx that can guarantee success. What is the most appropriate management to improve menorrhagia in this pt? \\n'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# !pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "# !pip install -q datasets bitsandbytes einops wandb\n",
        "# !pip install sentencepiece\n",
        "\n",
        "clear_output()\n",
        "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
      ],
      "metadata": {
        "id": "muzwGjNIPzBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-gptq\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "soyRX7F035IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = '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'"
      ],
      "metadata": {
        "id": "UE3lGFAN0M6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FLAN-T5**"
      ],
      "metadata": {
        "id": "JBeabGl8ykT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "u5Plpy5wyzNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "# clear_output()\n",
        "\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\n",
        "clear_output()\n",
        "\n"
      ],
      "metadata": {
        "id": "Qt1aj5KfRebL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6a6ee6e1-1dc3-4d92-f99d-98104730da6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-9a110a83f797>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/flan-t5-xxl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/flan-t5-xxl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'T5ForConditionalGeneration' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5inputs = tokenizer(\n",
        "    [f\"\"\"Question: Select the item from this list which is \"\n",
        " {item['question']}\". Context: * {\" * \".join(item['options'])}\"\"\"\n",
        "  for index, item in qa_data.iloc[1500:].iterrows()], return_tensors=\"pt\", padding=True\n",
        ")"
      ],
      "metadata": {
        "id": "OV3S9Hx0QiBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(t5inputs['input_ids']), len(t5inputs['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHKH80TFmdLk",
        "outputId": "ff8eee0c-0c1f-45c9-e7ef-7735e6d5f689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(206, 206)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_sequences = model.generate(\n",
        "    input_ids=t5inputs['input_ids'],max_new_tokens=20,\n",
        "    attention_mask=t5inputs[\"attention_mask\"],\n",
        "    do_sample=False,  # disable sampling to test if batching affects output\n",
        ")"
      ],
      "metadata": {
        "id": "CYc_NmQJQ5HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_output = []"
      ],
      "metadata": {
        "id": "WIXyvJMBu-7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = (tokenizer.batch_decode(output_sequences, skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "p5u1nlRLpAB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for value in result:\n",
        "  final_output.append(value)\n",
        "len(final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Aw7rwSVl37",
        "outputId": "cb5dbfee-453f-4aa0-b3cc-692b6a43c612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1706"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_output[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vt6RySCgixJ",
        "outputId": "cc242bbb-5314-4eed-b3a2-273aa777cc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e.', 'e.', 'c.', 'd.', 'd.', 'e. Parietal cortex', 'd.', 'd.', 'e.', 'c.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['Predicted_answer'] = final_output\n",
        "qa_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "Hl3FBEj3Pgpf",
        "outputId": "55172204-dce3-4ba5-be54-3d6aff0cce94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  [1. A 65yo man presents with painless hematuri...   \n",
              "1  [2. A 74yo smoker presented to his GP with cou...   \n",
              "2  [3. A 44yo woman has lost weight over 12 month...   \n",
              "3  [4. A 79yo anorexic male complains of thirst a...   \n",
              "4  [5. A 64yo man has recently suffered from an M...   \n",
              "\n",
              "                                             options  \\\n",
              "0  [a. US Abdomen\\n, b. Flexible cystoscopy\\n, c....   \n",
              "1  [a. Pseudocushing syndrome\\n, b. Conns disease...   \n",
              "2  [a. Thyroid antibodies\\n, b. TFT\\n, c. ECG\\n, ...   \n",
              "3  [a. BPH\\n, b. Prostate carcinoma\\n, c. Chronic...   \n",
              "4  [a. Lofepramine\\n, b. Dosulepin\\n, c. Citalopr...   \n",
              "\n",
              "                                              answer Predicted_answer  \n",
              "0  [Ans. The key is B. Flexible cystoscopy. [Pain...               e.  \n",
              "1  [Ans. The key is C. Ectopic ACTH. [The patient...               e.  \n",
              "2  [Ans. The key is B. TFT. [The patient has paro...               c.  \n",
              "3         [Ans. The key is B. Prostate Carcinoma.\\n]               d.  \n",
              "4  [Ans. The key is C. Citalopram. [Among SSRIs S...               d.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1f1ce53-b956-45b9-9a32-6b1d51f0b2a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>options</th>\n",
              "      <th>answer</th>\n",
              "      <th>Predicted_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1. A 65yo man presents with painless hematuri...</td>\n",
              "      <td>[a. US Abdomen\\n, b. Flexible cystoscopy\\n, c....</td>\n",
              "      <td>[Ans. The key is B. Flexible cystoscopy. [Pain...</td>\n",
              "      <td>e.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2. A 74yo smoker presented to his GP with cou...</td>\n",
              "      <td>[a. Pseudocushing syndrome\\n, b. Conns disease...</td>\n",
              "      <td>[Ans. The key is C. Ectopic ACTH. [The patient...</td>\n",
              "      <td>e.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[3. A 44yo woman has lost weight over 12 month...</td>\n",
              "      <td>[a. Thyroid antibodies\\n, b. TFT\\n, c. ECG\\n, ...</td>\n",
              "      <td>[Ans. The key is B. TFT. [The patient has paro...</td>\n",
              "      <td>c.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[4. A 79yo anorexic male complains of thirst a...</td>\n",
              "      <td>[a. BPH\\n, b. Prostate carcinoma\\n, c. Chronic...</td>\n",
              "      <td>[Ans. The key is B. Prostate Carcinoma.\\n]</td>\n",
              "      <td>d.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[5. A 64yo man has recently suffered from an M...</td>\n",
              "      <td>[a. Lofepramine\\n, b. Dosulepin\\n, c. Citalopr...</td>\n",
              "      <td>[Ans. The key is C. Citalopram. [Among SSRIs S...</td>\n",
              "      <td>d.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1f1ce53-b956-45b9-9a32-6b1d51f0b2a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1f1ce53-b956-45b9-9a32-6b1d51f0b2a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1f1ce53-b956-45b9-9a32-6b1d51f0b2a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data.to_csv('Flan-t5_results_12thJuly.csv')"
      ],
      "metadata": {
        "id": "wwg7MzinTtHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BIO-GPT**"
      ],
      "metadata": {
        "id": "0CJM90PRy4jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BioGptTokenizer, BioGptModel, BioGptForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "cg1Av35TTvtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "\n",
        "# Download the model from HF and store it locally, then reference its location here:\n",
        "quantized_model_dir = \"/path/to/TheBloke_WizardLM-Uncensored-Falcon-7B-GPTQ\"\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(quantized_model_dir, use_fast=False)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(quantized_model_dir, device=\"cuda:0\", use_triton=False, use_safetensors=True, torch_dtype=torch.float32, trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "LqGyacyz4Mwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# med_qa = sparknlp_jsl.annotators.MedicalQuestionAnswering\\\n",
        "#     .pretrained(\"medical_qa_biogpt\",\"en\",\"clinical/models\")\\\n",
        "#     .setInputCols([\"document_question\", \"document_context\"])\\\n",
        "#     .setOutputCol(\"answer\")\\\n",
        "#     .setMaxNewTokens(30)\\\n",
        "#     .setTopK(1)\\\n",
        "#     .setQuestionType(\"short\") # \"short\""
      ],
      "metadata": {
        "id": "DC0Yk1pIpYsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del model\n",
        "gpt_model = BioGptForCausalLM.from_pretrained(\n",
        "  'microsoft/biogpt',\n",
        "  load_in_8bit=True,\n",
        "  max_memory=f'{int(torch.cuda.mem_get_info()[0]/1024**3)-2}GB')\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "9msZL2Rn8nqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\", padding_side='left')\n",
        "# model = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "_75399Mfy1x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "   print(\"Training on GPU\")\n",
        "   device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbt5ToIa2RY6",
        "outputId": "a6e518c4-6e60-483e-9992-b7f9984fd375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "q_list = []"
      ],
      "metadata": {
        "id": "9dW1mtriaxu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regex_for_quest = re.compile(r\"^.*[a-z]\\.\\s|^.*[a-z]\\:\\s{0,4}\")\n",
        "def find_question_sentence(text):\n",
        "  # global quest\n",
        "  # print (text)\n",
        "  quest = None\n",
        "  if len(text) == 0:\n",
        "    quest = []\n",
        "  elif len(text) == 1:\n",
        "    if ('What'in text[0]) or ('Which' in text[0]) or ('Choose' in text[0]):\n",
        "      quest = text\n",
        "      # print ('show', quest)\n",
        "  elif len(text)>=1:\n",
        "    for i in range(len(text)):\n",
        "      # print (text[i])\n",
        "      if 'What' in text[i]:\n",
        "        quest = ['What' + text[i].split('What')[1]]\n",
        "        # print ('what')\n",
        "        break\n",
        "      elif 'Which' in text[i]:\n",
        "        quest = ['Which' + text[i].split('Which')[1]]\n",
        "        # print ('which')\n",
        "        break\n",
        "      elif 'Choose' in text[i]:\n",
        "        quest = ['Choose' + text[i].split('Choose')[1]]\n",
        "        # print ('choose')\n",
        "        break\n",
        "      elif 'Select' in text[i]:\n",
        "        quest = ['Select' + text[i].split('Select')[1]]\n",
        "        # print ('Select')\n",
        "        break\n",
        "      elif ('?' in text[i]):\n",
        "        # print (text[i])\n",
        "        if ('.' in text[i]):\n",
        "         quest = [(text[i].split('.'))[1]]\n",
        "        else:\n",
        "          quest = text[i-1:i+1]\n",
        "        # print ('?')\n",
        "        break\n",
        "      elif (re.search(regex_for_quest, text[i])):\n",
        "        # index = (re.search(regex_for_quest, text[i]).end())\n",
        "        # quest = text[i][index:]\n",
        "        quest = []\n",
        "        # print ('regex_match')\n",
        "      else:\n",
        "        continue\n",
        "  # input('press any key')\n",
        "  # print (quest)\n",
        "  return quest"
      ],
      "metadata": {
        "id": "H54G7AqoylLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INqvNL5RXES_",
        "outputId": "a5ec2aed-8ca1-46b0-d8f9-2f2e8d0a909d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader.tagged import sent_tokenize\n",
        "# from nltk.tokenize import sent_tokenize\n",
        "def sent_tokenise(x):\n",
        "  q_sentence = sent_tokenize(str(x))\n",
        "  # print (q_sentence[-1])\n",
        "  return_value = q_sentence[-1].split('?')[0]\n",
        "  return return_value+'?'"
      ],
      "metadata": {
        "id": "RrKtdGbPWtOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['question_sentence'] = qa_data['question'].apply(lambda x:sent_tokenise(x))\n",
        "qa_data['question_sentence'] = qa_data['question_sentence'].explode('question_sentence')"
      ],
      "metadata": {
        "id": "0adTD7BqtSKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data.to_csv('Data_with_question_sentences(19Jul).csv')"
      ],
      "metadata": {
        "id": "Eqo4t_BfLwol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A 28yo woman at 39wk gestation is in labor. She develops abdominal pain and HR=125bpm,\n",
        "BP=100/42mmHg, temp=37.2C and saturation=99%. Exam: lower abdomen is exquisitely tender.\n",
        "CTG=prv normal, now showing reduced variability and late deceleration develops with slow\n",
        "recovery. She has had 1 prv LSCS for a breech baby. Choose the most appropriate CS\n",
        "complication for this lady?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-IEowU28OaV",
        "outputId": "996adcba-4d22-4d90-e1cc-ffc0e455cfae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a. US Abdomen\\n',\n",
              " 'b. Flexible cystoscopy\\n',\n",
              " 'c. MRI\\n',\n",
              " 'd. Nuclear imaging\\n',\n",
              " 'e. PSA\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del biogpt_inputs\n",
        "biogpt_inputs = tokenizer([f\"\"\"Example:{item['']} Question: \" {item['question_sentence']}\". Context: \"{item['question']}\".\"Is it Option :{(item['options'])} yes/no?\"\"\"\n",
        "  for index, item in qa_data_exploded.iloc[:10].iterrows()], return_tensors=\"pt\", padding=True)"
      ],
      "metadata": {
        "id": "O0ny-NmOzj4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "biogpt_output_sequences = model.generate(\n",
        "    input_ids=biogpt_inputs['input_ids'].to(device),max_new_tokens=20,\n",
        "    attention_mask=biogpt_inputs[\"attention_mask\"],\n",
        "    do_sample=False,  # disable sampling to test if batching affects output\n",
        ")"
      ],
      "metadata": {
        "id": "p6c4xv6A0R5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = (tokenizer.batch_decode(biogpt_output_sequences, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "ZSHRAAOY0qu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['question_sentence'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeq_TSmIBQvC",
        "outputId": "cc550ec5-b3dd-4927-ba40-3bcb99c453c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3cSCnX4-H9f",
        "outputId": "d79e1078-a012-401a-e28b-5db1eb77d8d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Question: \"[\\'1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\\\\ n\\']\". Context: \"1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\". \"Is it Option: a. US Abdomen yes / no?',\n",
              " 'Question: \"[\\'1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\\\\ n\\']\". Context: \"1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\". \"Is it Option: b. Flexible cystoscopy yes / no?',\n",
              " 'Question: \"[\\'1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\\\\ n\\']\". Context: \"1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\". \"Is it Option: c. MRI yes / no?',\n",
              " 'Question: \"[\\'1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\\\\ n\\']\". Context: \"1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\". \"Is it Option: d. Nuclear imaging yes / no?',\n",
              " 'Question: \"[\\'1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\\\\ n\\']\". Context: \"1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\". \"Is it Option: e. PSA yes / no?',\n",
              " 'Question: \"[\\'What is the most probable dx?\\\\ n\\']\". Context: \"2. A 74yo smoker presented to his GP with cough and SOB. Exam revealed pigmentation of the oral\". \"Is it Option: a. Pseudocushing syndrome yes / no?']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**{k: v.unsqueeze(0) for k, v in ip.items()}, labels=0)"
      ],
      "metadata": {
        "id": "zAZXJ-0HD4QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for value in result:\n",
        "  final_output.append(value)\n",
        "len(final_output)"
      ],
      "metadata": {
        "id": "VbOycUDQB8gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Falcon-7b"
      ],
      "metadata": {
        "id": "KC71Ko7Sn9eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git lfs install\n",
        "# !git clone https://huggingface.co/tiiuae/falcon-7b-instruct /content/sample_data/Falcon"
      ],
      "metadata": {
        "id": "rMxC37VUYFNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "# model_name = \"ybelkada/falcon-7b-sharded-bf16\"\n",
        "# model_name = \"Sandiago21/falcon-7b-prompt-answering\"\n",
        "model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    local_files_only=True,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False\n",
        "\n",
        "# self.tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)\n",
        "#         self.model = AutoModel.from_pretrained(model_name, local_files_only=True)\n"
      ],
      "metadata": {
        "id": "Y7XHQctTmqX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# model = PeftModel.from_pretrained(model, model_name)\n",
        "\n",
        "generation_config = model.generation_config\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.max_new_tokens = 32\n",
        "generation_config.use_cache = False\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# model.eval()\n",
        "# if torch.__version__ >= \"2\":\n",
        "#     model = torch.compile(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "edf6f5ea0f1f41e5bebd476828f85ac3",
            "cf02321e084a452990f0b8a09a832950",
            "d7882636f76b4d3d9572237c5483c1fb",
            "8b81ee1777774393bfdbda1b7eb71261",
            "4e3e281191284702bde254d901b13ea9",
            "b32296356fc443f28b3f5d99bec9ba64",
            "0f8d2a2ecc804ad3aadc3d206889acf9",
            "92d674e8be0a437ba32ffef24dfaaa55",
            "31c0cbeec3bb4cf792f3566dc20adceb",
            "1fd280233b46416b9871e2163287b621",
            "ba57c28b5beb43bd90e4c53edab6bd82",
            "98649fd6235442268643f875afbfd097",
            "892a51150d9942d983784bd8cb82b640",
            "a52e6cbcc3914d8b88dbd3983cd040a9",
            "3e5b01b4bfce4fa69a0a9584809b8e46",
            "617e7a1ce243494cbc0e4a14db1fa0c6",
            "94c9a9052faa4663947864569787948b",
            "d2580a0b5a5f42988cf1666d87c3b7b3",
            "d84330c7ffb0448ca749bd982d171e4c",
            "99d6093b699849a788044584991181a7",
            "2d6497b836714285906dd72c5491fa39",
            "ae5602d926a942c7ae33131daac3bf77",
            "35f74a68d5c641fea1adea64bc3faef7",
            "01f9f907c8b1405a82e559d11b7108c6",
            "69c09c842f524662b7e3f1bd7109df2a",
            "4b1d671afe044bce908e8b6e52476371",
            "2416fdce36714fd193ccb9b61acfaf8c",
            "52e2ddfabd3b4d07bb593c5933bf54a0",
            "8bf47789954747d99c87d0a41d085475",
            "6ec3778c1a874314a3d588df40be27f6",
            "b260d01b2cf942538b67d7166f800143",
            "93589b65390a4f64805867e3b3350ff5",
            "a604fd469460453a9f6d114bb9adc586"
          ]
        },
        "id": "ks-nMjpEuPFD",
        "outputId": "c846a591-c57a-4a81-f660-20fe223d8eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/180 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edf6f5ea0f1f41e5bebd476828f85ac3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98649fd6235442268643f875afbfd097"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35f74a68d5c641fea1adea64bc3faef7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_prompt(prompt: str, options: list) -> str:\n",
        "#     return f\"\"\"\n",
        "#     <human>: For question {qa_data['question'][0][0]}, given options are {qa_data['options'][0]} {'The key is B. Flexible cystoscopy.'}\n",
        "\n",
        "#     <human>: for question {prompt}, given options are {options}\\n{'answer is:'}\n",
        "#     <assistant>:\n",
        "#     \"\"\".strip()"
      ],
      "metadata": {
        "id": "TbEK7RVH7yll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(i):\n",
        "  check_prompt = f\"\"\"From the options given below, answer the following question else, say I don't know dear!\n",
        "\n",
        "  Context:\n",
        "  {qa_data['question'][0]}\\n{qa_data['options'][0]}\\n{qa_data['answer'][0]}\n",
        "  {qa_data['question'][1]}\\n{qa_data['options'][1]}\\n{qa_data['answer'][1]}\n",
        "  {qa_data['question'][2]}\\n{qa_data['options'][2]}\\n{qa_data['answer'][2]}\n",
        "  {qa_data['question'][3]}\\n{qa_data['options'][3]}\\n{qa_data['answer'][3]}\n",
        "  {qa_data['question'][4]}\\n{qa_data['options'][4]}\\n{qa_data['answer'][4]}\n",
        "\n",
        "  Question: {qa_data['question'][i]}\\nOptions{qa_data['options'][i]}\"\"\"\n",
        "  return check_prompt"
      ],
      "metadata": {
        "id": "Ow2wEqmIvVCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # <human>: {qa_data['question'][1][0]}\\n{qa_data['options'][1]}\\n{qa_data['answer'][1]}\n",
        "    # <human>: {qa_data['question'][2][0]}\\n{qa_data['options'][2]}\\n{qa_data['answer'][2]}\n",
        "    # <human>: {qa_data['question'][3][0]}\\n{qa_data['options'][3]}\\n{qa_data['answer'][3]}\n",
        "    # <human>: {qa_data['question'][4][0]}\\n{qa_data['options'][4]}\\n{qa_data['answer'][4]}\n",
        "\n",
        "# falcon_inputs =  generate_prompt [\"\"\"Question: Select the item from this list which is \"\n",
        "#  {item['question']}\". Context: * {\" * \".join(item['options'])}\"\"\"\n",
        "#   for index, item in qa_data.iloc[:10].iterrows()], return_tensors=\"pt\", padding=True"
      ],
      "metadata": {
        "id": "XxpbbZF-8czr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wst3hyStCSZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['Falcon_ans'] = pd.Series(dtype='str')\n",
        "\n",
        "for i in range(6,7):\n",
        "  input_prompt = generate_prompt(i)\n",
        "  # print (input_prompt)\n",
        "  input_ids = tokenizer(input_prompt, return_tensors=\"pt\").input_ids\n",
        "  input_ids = input_ids.to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "          input_ids=input_ids,\n",
        "          generation_config=generation_config,\n",
        "          return_dict_in_generate=True,\n",
        "          output_scores=True,\n",
        "      )\n",
        "\n",
        "  response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
        "  qa_data['Falcon_ans'].iloc[i] = response\n",
        "\n",
        "  print(response)\n",
        "  # clear_output()"
      ],
      "metadata": {
        "id": "G6oqohgo7p9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['answer'][6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qpplc66GOP9",
        "outputId": "e8b9c9e8-62a6-44f4-f8a4-c1aeaab7d616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ans. The key is A. Achalasia. [Dysphagia for both solid and liquid or prominently liquid suggest achalasia where dysphagia to solid suggest stricture. Also gross dilatation of oesophagus with smooth narrowing at lower end is seen in achalasia. In achalasia dysphagia is usually described as progressive].\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del input_ids, outputs\n",
        "input_ids = tokenizer(check_prompt, return_tensors=\"pt\").input_ids\n",
        "input_ids = input_ids.to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=generation_config,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-QhQR2o9n_E",
        "outputId": "c1559462-ad45-4bb3-ccbb-64b3d36857b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From the options given below, answer the following question else, say I don't know dear!\n",
            "\n",
            "Context:\n",
            "1. A 65yo man presents with painless hematuria, IVU is normal, prostate is mildly enlarged with mild frequency. What is the most appropriate next step?\n",
            "\n",
            "['a. US Abdomen\\n', 'b. Flexible cystoscopy\\n', 'c. MRI\\n', 'd. Nuclear imaging\\n', 'e. PSA\\n']\n",
            "['Ans. The key is B. Flexible cystoscopy. [Painless hematuria in an elderly (here 65 years old man) indicates carcinoma bladder for which flexible cystoscopy is done.\\n']\n",
            "2. A 74yo smoker presented to his GP with cough and SOB. Exam revealed pigmentation of the oral\n",
            "\n",
            "['a. Pseudocushing syndrome\\n', 'b. Conns disease\\n', 'c. Ectopic ACTH\\n', 'd. Cushings disease\\n', 'e. Hypothyroidism\\n']\n",
            "['Ans. The key is C. Ectopic ACTH. [The patient is smoker and probably developed squamous cell lung cancer which is working as a tumour producing ectopic ACTH causing pigmentation. Resulting raised cortisole is leading to diabetes and hypokalemia (though small cell carcinoma is usual cause but squamous cell carcinoma can produce ectopic ACTH as paraneoplastic syndrome also)].\\n']\n",
            "3. A 44yo woman has lost weight over 12 months. She has also noticed episodes where her heart\n",
            "\n",
            "['a. Thyroid antibodies\\n', 'b. TFT\\n', 'c. ECG\\n', 'd. Echocardiogram\\n', 'e. Plasma glucose\\n']\n",
            "['Ans. The key is B. TFT. [The patient has paroxysmal atrial fibrillation That is why there is no arrhythmia in between attacks. From the given option TFT is the appropriate test as thyrotoxycosis is a leading cause of paroxysmal atrial fibrillation and this ladies weight loss also makes thyrotoxycosis as the probable cause here].\\n']\n",
            "4. A 79yo anorexic male complains of thirst and fatigue. He has symptoms of frequency, urgency\n",
            "\n",
            "['a. BPH\\n', 'b. Prostate carcinoma\\n', 'c. Chronic pyelonephritis\\n', 'd. Benign nephrosclerosis\\n']\n",
            "['Ans. The key is B. Prostate Carcinoma.\\n']\n",
            "5. A 64yo man has recently suffered from an MI and is on aspirin, atorvastatin and ramipril. He has\n",
            "\n",
            "['a. Lofepramine\\n', 'b. Dosulepin\\n', 'c. Citalopram\\n', 'd. Fluoxetine\\n', 'e. Phenelzine\\n']\n",
            "['Ans. The key is C. Citalopram. [Among SSRIs Sertraline is the drug of choice for ischemic heart disease. Next choice is citalopram (as it is often related to torsades de pointes it is not 1st choice). If SSRI cannot be used Mirtazapine is recommended as next antidepressant].\\n']\n",
            "\n",
            "Question: ['8. A man undergoes a pneumonectomy. After surgery, invs show hyponatremia. What could be the\\n', 'cause of the biochemical change?\\n']\n",
            "Options['a. Removal of hormonally active tumor\\n', 'b. Excess dextrose\\n', 'c. Excess colloid\\n', 'd. Excessive K+\\n', 'e. Hemodilution\\n']\n",
            "['Ans. The key is C. Excessive K+. [The patient is hyponatremic after pneumonectomy. This is due to excessive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['answer'][7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inQt6WOByNl8",
        "outputId": "da28ad03-b29c-4316-8705-d507e3d9eced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Ans. The key is A. Removal of harmonically active tumour. [Ectopic ACTH secreting tumour causes hypernatremia and body's homeostatic mechanism try to lower the level of high sodium and do a lesser degree though sodium remains in hypernatremic level or even it may be normal (this question does not mention any preoperative hypernatremia). Removal of that tumour results in negative sodium balance for time being which results hyponatremia while gradually it tends to rise again to normal level].\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MedAlpaca"
      ],
      "metadata": {
        "id": "m2qoNLf5wV55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/medalpaca/medalpaca-7b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKSPYVRAONGU",
        "outputId": "9acc689b-b3e9-45a4-b99f-ff0309c7e66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n",
            "Cloning into 'medalpaca-7b'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 34\u001b[K\n",
            "Unpacking objects: 100% (37/37), 136.60 KiB | 2.20 MiB/s, done.\n",
            "Filtering content: 100% (5/5), 5.10 GiB | 3.74 MiB/s, done.\n",
            "Encountered 3 file(s) that may not have been copied correctly on Windows:\n",
            "\tpytorch_model-00003-of-00003.bin\n",
            "\tpytorch_model-00001-of-00003.bin\n",
            "\tpytorch_model-00002-of-00003.bin\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "87exCY7m0F2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"/content/medalpaca-7b\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/medalpaca-7b\")\n",
        "clear_output()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVSmToq6YxkJ",
        "outputId": "6a57239c-1539-46b2-84a7-affead463cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Hello, doctor'\n",
        "batch = tokenizer(\n",
        "            sentence,\n",
        "            return_tensors=\"pt\",\n",
        "            add_special_tokens=False\n",
        "        )\n",
        "with torch.no_grad():\n",
        "    generated = model.generate(inputs = batch[\"input_ids\"], max_length=200, do_sample=True, top_k=50)\n",
        "    print('model predict: ',tokenizer.decode(generated[0]))\n"
      ],
      "metadata": {
        "id": "3-feqtTQxF4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BioMedLM**"
      ],
      "metadata": {
        "id": "nVA1ZGoXIgx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "RDAUvPNZK6AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# biomedlm_model = BioGptForCausalLM.from_pretrained(\n",
        "#   'stanford-crfm/BioMedLM',\n",
        "#   load_in_8bit=True,\n",
        "#   max_memory=f'{int(torch.cuda.mem_get_info()[0]/1024**3)-2}GB')\n",
        "\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "1Nw5a14fIY4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHie_RlllOIm",
        "outputId": "b947e6c5-1285-4a14-93b2-1ff115041e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# device = torch.device(\"cuda\")\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"stanford-crfm/BioMedLM\")\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"stanford-crfm/BioMedLM\")\n",
        "# .to(device)\n"
      ],
      "metadata": {
        "id": "e340Kckqh6fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids = tokenizer.encode(\n",
        "#     \"Photosynthesis is \", return_tensors=\"pt\"\n",
        "# ).to(device)\n",
        "\n",
        "# sample_output = model.generate(input_ids, do_sample=True, max_length=50, top_k=50)\n",
        "\n",
        "# print(\"Output:\\n\" + 100 * \"-\")\n",
        "# print(tokenizer.decode(sample_output[0], skip_"
      ],
      "metadata": {
        "id": "EjG5fN9biZZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# biomedlm_model = AutoModelForCausalLM.from_pretrained(\"stanford-crfm/BioMedLM\",\n",
        "#   max_memory=f'{int(torch.cuda.mem_get_info()[0]/1024**3)-2}GB')"
      ],
      "metadata": {
        "id": "sk8RElT3O_DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# biomedlm_tokenizer = AutoTokenizer.from_pretrained(\"stanford-crfm/BioMedLM\")"
      ],
      "metadata": {
        "id": "5uU7XrXKIwHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = \"https://api-inference.huggingface.co/models/stanford-crfm/BioMedLM\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})"
      ],
      "metadata": {
        "id": "oZgVOUms7SjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJl0ZP4CIdW9",
        "outputId": "81225f67-de28-4aad-fd0d-f6ef903c0d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model stanford-crfm/BioMedLM is too large to be loaded automatically (10GB > 10GB). For commercial use please use PRO spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference API - Falcon 7b"
      ],
      "metadata": {
        "id": "azAFdupeKorW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "API_URL = \"https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct\"\n",
        "headers = {\"Authorization\": f\"Bearer {'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'}\", \"content-Type\":\"application/json\"}"
      ],
      "metadata": {
        "id": "UPQ05oqcN-19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del query\n",
        "def query(payload):\n",
        "    data = json.dumps(payload)\n",
        "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
        "    return json.loads(response.content.decode(\"utf-8\"))\n"
      ],
      "metadata": {
        "id": "7h4oXmy4KnhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import re\n"
      ],
      "metadata": {
        "id": "QSXusjxh4phS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output = []\n",
        "for index, item in qa_data.iloc[1369:].iterrows():\n",
        "  question = (re.split(r'\\d\\.',(str(''.join(item['question'])))))[1]+ ''\n",
        "  options = str(''.join(item['options']))\n",
        "  input = question + options + 'The correct answer is'\n",
        "  # print (input)\n",
        "  print (\"ans\")\n",
        "  # del data\n",
        "  data = query(\n",
        "      {\n",
        "          \"inputs\": input,\n",
        "          # \"context\": str(''.join(item['question_sentence']))\n",
        "          # 'context': 'The correct answer is '\n",
        "      }\n",
        "  )\n",
        "  output.append((data))\n",
        "  print (data)\n",
        "  print ('next')\n",
        "  clear_output()\n",
        "  print (len(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDWfMWLpyb-1",
        "outputId": "599e15c0-ad0a-4aa5-fe67-21ae9a14ce40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['options'][7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h1-IffjEUoM",
        "outputId": "bf46e2ae-f63a-4795-8957-cdbfd42e365a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a. Removal of hormonally active tumor\\n',\n",
              " 'b. Excess dextrose\\n',\n",
              " 'c. Excess colloid\\n',\n",
              " 'd. Excessive K+\\n',\n",
              " 'e. Hemodilution\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['Falcon_25Jul'] = ''\n",
        "qa_data['Falcon_25Jul'].iloc[:1368] = output[:1368]\n",
        "qa_data['Falcon_25Jul'].iloc[1368] = ''\n",
        "qa_data['Falcon_25Jul'].iloc[1369:] = output[1368:]\n"
      ],
      "metadata": {
        "id": "Inq8_kXXsAtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911d01e1-65d5-4178-851a-9bc67f5474be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-7d640e923c7d>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  qa_data['Falcon_25Jul'].iloc[:1368] = output[:1368]\n",
            "<ipython-input-26-7d640e923c7d>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  qa_data['Falcon_25Jul'].iloc[1368] = ''\n",
            "<ipython-input-26-7d640e923c7d>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  qa_data['Falcon_25Jul'].iloc[1369:] = output[1368:]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ-rEWKJGYdK",
        "outputId": "7038630e-fa10-424f-e907-d5d13c656c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1705"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data.to_csv('Falcon_results_25Jul.csv')\n"
      ],
      "metadata": {
        "id": "sIhAx5Rv9BUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference-Flan XXL"
      ],
      "metadata": {
        "id": "J4mw_JlRIS9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/google/flan-t5-xxl\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n"
      ],
      "metadata": {
        "id": "Ldmfwr3uIVcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from IPython.display import clear_output\n",
        "\n",
        "output = []\n",
        "for index, item in qa_data.iloc[:1368].iterrows():\n",
        "  question = (re.split(r'\\d\\.',(str(''.join(item['question'])))))[1]+ ''\n",
        "  options = str(''.join(item['options']))\n",
        "  input = question + options\n",
        "  print (input)\n",
        "  print (\"ans\")\n",
        "  # del data\n",
        "  data = query(\n",
        "      {\n",
        "          \"inputs\": input,\n",
        "      }\n",
        "  )\n",
        "  output.append((data))\n",
        "  print (data)\n",
        "  print ('next')\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "8wgoi_KoIZ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(output)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY5qtss2Oq6C",
        "outputId": "d2207bba-bfbc-4d52-cad1-2a2d1cc16f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': 'a.'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.DataFrame(output).to_csv('Flan-xxl_results_0to100_new.csv')\n",
        "# pd.DataFrame(output[100:]).to_csv('Flan-xxl_results_100to200_new.csv')\n",
        "pd.DataFrame(output).to_csv('Flan-xxl_results_new_17Jul.csv')"
      ],
      "metadata": {
        "id": "1XrFPEMlOt2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['question'][1368:1369]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQFJenzzQIaz",
        "outputId": "0c5d4dbe-6a2a-40d0-f423-54e75ee0e4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1368    []\n",
              "Name: question, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference - MedAlpaca"
      ],
      "metadata": {
        "id": "8aPIvMuFzhWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://tz3i01jao3mit3ls.eu-west-1.aws.endpoints.huggingface.cloud \\\n",
        "-X POST \\\n",
        "-d '{\"inputs\":\"An 80yo man presented with pain in his lower back and hip. He also complains of waking up in\\n'\\'',\\n '\\''the night to go to the washroom and has urgency as well as dribbling. What is the most likely dx?\\n'\\''a. BPH\\n'\\'',\\n '\\''b. Prostatitis\\n'\\'',\\n '\\''c. UTI\\n'\\'',\\n '\\''d. Prostate carcinoma\\n'\\'',\\n '\\''e. Bladder carcinoma\\n'\\''\"}' \\\n",
        "-H \"Authorization: Bearer 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\" \\\n",
        "-H \"Content-Type: application/json\""
      ],
      "metadata": {
        "id": "_lTaV8080LJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9b600d-3b6f-433c-ca94-f02b1f9e85f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"generated_text\":\"\\nAnswer:b\"}]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def prepare_input(item):\n",
        "  quest = (''.join(eval(item['context'])).replace('\\n', ''))\n",
        "  quest = re.sub('\\d{0,4}\\.','',quest)\n",
        "  quest = quest.strip()\n",
        "  # print (quest)\n",
        "  option = item['options'].replace('\\\\n','')\n",
        "  # option = 'From the given options - '+ (', '.join(eval(option))) + '. '\n",
        "  option = (', '.join(eval(option))) + '. '\n",
        "  quest_sent = (item['question_sentence'].replace('\\\\n',''))\n",
        "  # print (type(quest_sent), quest_sent)\n",
        "  quest_sent = re.sub(\",|\\'\",'', quest_sent)\n",
        "  final_input = quest + '. ' +  quest_sent + ' ' + option + '\\nThe correct answer is'\n",
        "  return final_input"
      ],
      "metadata": {
        "id": "nQ2vj_BD-zbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response_list = []\n",
        "\n",
        "for index, item in qa_data.iloc[1369:].iterrows():\n",
        "  medalpaca_ip = prepare_input(item)\n",
        "  # print (medalpaca_ip)\n",
        "  json_data = {\n",
        "    'inputs': medalpaca_ip,\n",
        "  }\n",
        "  # print ('medalpaca_ip', medalpaca_ip)\n",
        "  response = requests.post('https://tz3i01jao3mit3ls.eu-west-1.aws.endpoints.huggingface.cloud', headers=headers, json=json_data)\n",
        "  response_list.append(response.text)\n",
        "  # print (response.text)\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "RZ8hW9KB7Csu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(response_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxMpldFfNgub",
        "outputId": "500560ea-57ce-4916-f25e-bd754989f4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1705"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    'Authorization': 'Bearer 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',\n",
        "    'Content-Type': 'application/json',\n",
        "}\n",
        "\n",
        "json_data = {\n",
        "    'inputs': medalpaca_ip,\n",
        "}\n",
        "\n",
        "response = requests.post('https://tz3i01jao3mit3ls.eu-west-1.aws.endpoints.huggingface.cloud', headers=headers, json=json_data)\n",
        "\n",
        "print (response.text)"
      ],
      "metadata": {
        "id": "KDYUmeCvz_Qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057281f5-6234-446a-af2e-581346fd3d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"generated_text\":\"c. MRI.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data['medalpaca_answers'] = ''\n",
        "qa_data['medalpaca_answers'].iloc[:1368] = response_list[:1368]\n",
        "qa_data['medalpaca_answers'].iloc[1368] = []\n",
        "qa_data['medalpaca_answers'].iloc[1369:] = response_list[1368:]\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "s7rUVnnMRhHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(qa_data['medalpaca_answers'].iloc[1369:]), len(response_list[1368:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQVpKl-EmiiP",
        "outputId": "1b810c8a-0e2c-4b42-e2b6-e1b7095e2d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(337, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data.to_csv('Medalpaca_results_26Jul.csv')"
      ],
      "metadata": {
        "id": "xyIQZezutYEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8512uBgUtwKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLAMA -2-70b"
      ],
      "metadata": {
        "id": "NqyTkqgjz4bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = meta-llama/Llama-2-70b-chat-hf \\\n",
        "!curl https://api-inference.huggingface.co/models/$model_id \\\n",
        "-X POST \\\n",
        "-d '{\"inputs\":\"An 80yo man presented with pain in his lower back and hip. He also complains of waking up in\\n'\\'',\\n '\\'\\'the night to go to the washroom and has urgency as well as dribbling. What is the most likely dx?\\n'\\'\\'a. BPH\\n'\\'\\',\\n \\'\\'\\'b. Prostatitis\\n'\\'',\\n '\\''c. UTI\\n'\\'',\\n '\\''d. Prostate carcinoma\\n'\\'',\\n '\\''e. Bladder carcinoma\\n'\\''\"}' \\\n",
        "-H \"Authorization: Bearer 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\" \\\n",
        "-H \"Content-Type: application/json\""
      ],
      "metadata": {
        "id": "U4Y6jTUyz2FE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wnbL0lFi_jDG",
        "GpeEla9i0M8x",
        "JBeabGl8ykT2",
        "0CJM90PRy4jZ",
        "KC71Ko7Sn9eW",
        "m2qoNLf5wV55",
        "nVA1ZGoXIgx5"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edf6f5ea0f1f41e5bebd476828f85ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf02321e084a452990f0b8a09a832950",
              "IPY_MODEL_d7882636f76b4d3d9572237c5483c1fb",
              "IPY_MODEL_8b81ee1777774393bfdbda1b7eb71261"
            ],
            "layout": "IPY_MODEL_4e3e281191284702bde254d901b13ea9"
          }
        },
        "cf02321e084a452990f0b8a09a832950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32296356fc443f28b3f5d99bec9ba64",
            "placeholder": "​",
            "style": "IPY_MODEL_0f8d2a2ecc804ad3aadc3d206889acf9",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "d7882636f76b4d3d9572237c5483c1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d674e8be0a437ba32ffef24dfaaa55",
            "max": 180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31c0cbeec3bb4cf792f3566dc20adceb",
            "value": 180
          }
        },
        "8b81ee1777774393bfdbda1b7eb71261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fd280233b46416b9871e2163287b621",
            "placeholder": "​",
            "style": "IPY_MODEL_ba57c28b5beb43bd90e4c53edab6bd82",
            "value": " 180/180 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "4e3e281191284702bde254d901b13ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32296356fc443f28b3f5d99bec9ba64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8d2a2ecc804ad3aadc3d206889acf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92d674e8be0a437ba32ffef24dfaaa55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c0cbeec3bb4cf792f3566dc20adceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fd280233b46416b9871e2163287b621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba57c28b5beb43bd90e4c53edab6bd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98649fd6235442268643f875afbfd097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_892a51150d9942d983784bd8cb82b640",
              "IPY_MODEL_a52e6cbcc3914d8b88dbd3983cd040a9",
              "IPY_MODEL_3e5b01b4bfce4fa69a0a9584809b8e46"
            ],
            "layout": "IPY_MODEL_617e7a1ce243494cbc0e4a14db1fa0c6"
          }
        },
        "892a51150d9942d983784bd8cb82b640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c9a9052faa4663947864569787948b",
            "placeholder": "​",
            "style": "IPY_MODEL_d2580a0b5a5f42988cf1666d87c3b7b3",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "a52e6cbcc3914d8b88dbd3983cd040a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d84330c7ffb0448ca749bd982d171e4c",
            "max": 2734158,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99d6093b699849a788044584991181a7",
            "value": 2734158
          }
        },
        "3e5b01b4bfce4fa69a0a9584809b8e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d6497b836714285906dd72c5491fa39",
            "placeholder": "​",
            "style": "IPY_MODEL_ae5602d926a942c7ae33131daac3bf77",
            "value": " 2.73M/2.73M [00:00&lt;00:00, 6.21MB/s]"
          }
        },
        "617e7a1ce243494cbc0e4a14db1fa0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94c9a9052faa4663947864569787948b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2580a0b5a5f42988cf1666d87c3b7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d84330c7ffb0448ca749bd982d171e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d6093b699849a788044584991181a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d6497b836714285906dd72c5491fa39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5602d926a942c7ae33131daac3bf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35f74a68d5c641fea1adea64bc3faef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01f9f907c8b1405a82e559d11b7108c6",
              "IPY_MODEL_69c09c842f524662b7e3f1bd7109df2a",
              "IPY_MODEL_4b1d671afe044bce908e8b6e52476371"
            ],
            "layout": "IPY_MODEL_2416fdce36714fd193ccb9b61acfaf8c"
          }
        },
        "01f9f907c8b1405a82e559d11b7108c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e2ddfabd3b4d07bb593c5933bf54a0",
            "placeholder": "​",
            "style": "IPY_MODEL_8bf47789954747d99c87d0a41d085475",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "69c09c842f524662b7e3f1bd7109df2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec3778c1a874314a3d588df40be27f6",
            "max": 281,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b260d01b2cf942538b67d7166f800143",
            "value": 281
          }
        },
        "4b1d671afe044bce908e8b6e52476371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93589b65390a4f64805867e3b3350ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_a604fd469460453a9f6d114bb9adc586",
            "value": " 281/281 [00:00&lt;00:00, 17.2kB/s]"
          }
        },
        "2416fdce36714fd193ccb9b61acfaf8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e2ddfabd3b4d07bb593c5933bf54a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf47789954747d99c87d0a41d085475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ec3778c1a874314a3d588df40be27f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b260d01b2cf942538b67d7166f800143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93589b65390a4f64805867e3b3350ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a604fd469460453a9f6d114bb9adc586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}